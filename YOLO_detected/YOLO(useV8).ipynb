{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "g5dvKZRXx8L2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "115a3da2-e032-4376-acd4-2f159491330f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.140 🚀 Python-3.10.6 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 24.3/107.7 GB disk)\n"
          ]
        }
      ],
      "source": [
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# simple test\n",
        "!yolo predict model=yolov8n.pt source='https://ultralytics.com/images/zidane.jpg'"
      ],
      "metadata": {
        "id": "qtJcuBD_cL-e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "009b09db-8e7c-42ab-ef57-727045e2c1e4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n",
            "100% 6.23M/6.23M [00:00<00:00, 68.7MB/s]\n",
            "Ultralytics YOLOv8.0.140 🚀 Python-3.10.6 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients\n",
            "\n",
            "Downloading https://ultralytics.com/images/zidane.jpg to 'zidane.jpg'...\n",
            "100% 165k/165k [00:00<00:00, 7.38MB/s]\n",
            "image 1/1 /content/zidane.jpg: 384x640 2 persons, 1 tie, 423.1ms\n",
            "Speed: 18.2ms preprocess, 423.1ms inference, 30.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.hub.download_url_to_file('https://ultralytics.com/assets/coco2017val.zip', 'tmp.zip')  # download (780M - 5000 images)\n",
        "!unzip -q tmp.zip -d datasets && rm tmp.zip\n",
        "\n",
        "!yolo val model=yolov8n.pt data=coco128.yaml"
      ],
      "metadata": {
        "id": "Z977_j4Icjd-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36ff459d-121a-42c9-e308-e413d3909265"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 780M/780M [00:07<00:00, 113MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.140 🚀 Python-3.10.6 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients\n",
            "\n",
            "Dataset 'coco128.yaml' images not found ⚠️, missing paths ['/content/datasets/coco128/images/train2017']\n",
            "Downloading https://ultralytics.com/assets/coco128.zip to '/content/datasets/coco128.zip'...\n",
            "100% 6.66M/6.66M [00:00<00:00, 70.2MB/s]\n",
            "Unzipping /content/datasets/coco128.zip to /content/datasets...\n",
            "Dataset download success ✅ (0.6s), saved to \u001b[1m/content/datasets\u001b[0m\n",
            "\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100% 755k/755k [00:00<00:00, 17.1MB/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco128/labels/train2017... 126 images, 2 backgrounds, 0 corrupt: 100% 128/128 [00:00<00:00, 1713.86it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/coco128/labels/train2017.cache\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:36<00:00,  4.60s/it]\n",
            "                   all        128        929       0.64      0.537      0.605      0.446\n",
            "                person        128        254      0.797      0.677      0.764      0.538\n",
            "               bicycle        128          6      0.514      0.333      0.315      0.264\n",
            "                   car        128         46      0.813      0.217      0.273      0.168\n",
            "            motorcycle        128          5      0.687      0.887      0.898      0.685\n",
            "              airplane        128          6       0.82      0.833      0.927      0.675\n",
            "                   bus        128          7      0.491      0.714      0.728      0.671\n",
            "                 train        128          3      0.534      0.667      0.706      0.604\n",
            "                 truck        128         12          1      0.332      0.473      0.297\n",
            "                  boat        128          6      0.226      0.167      0.316      0.134\n",
            "         traffic light        128         14      0.734        0.2      0.202      0.139\n",
            "             stop sign        128          2          1      0.992      0.995      0.701\n",
            "                 bench        128          9      0.839      0.582       0.62      0.365\n",
            "                  bird        128         16      0.921      0.728      0.864       0.51\n",
            "                   cat        128          4      0.875          1      0.995      0.791\n",
            "                   dog        128          9      0.603      0.889      0.785      0.585\n",
            "                 horse        128          2      0.597          1      0.995      0.518\n",
            "              elephant        128         17      0.849      0.765        0.9      0.679\n",
            "                  bear        128          1      0.593          1      0.995      0.995\n",
            "                 zebra        128          4      0.848          1      0.995      0.965\n",
            "               giraffe        128          9       0.72          1      0.951      0.722\n",
            "              backpack        128          6      0.589      0.333      0.376      0.232\n",
            "              umbrella        128         18      0.804        0.5      0.643      0.414\n",
            "               handbag        128         19      0.424     0.0526      0.165     0.0889\n",
            "                   tie        128          7      0.804      0.714      0.674      0.476\n",
            "              suitcase        128          4      0.635      0.883      0.745      0.534\n",
            "               frisbee        128          5      0.675        0.8      0.759      0.688\n",
            "                  skis        128          1      0.567          1      0.995      0.497\n",
            "             snowboard        128          7      0.742      0.714      0.747        0.5\n",
            "           sports ball        128          6      0.716      0.433      0.485      0.278\n",
            "                  kite        128         10      0.817       0.45      0.569      0.184\n",
            "          baseball bat        128          4      0.551       0.25      0.353      0.175\n",
            "        baseball glove        128          7      0.624      0.429      0.429      0.293\n",
            "            skateboard        128          5      0.846        0.6        0.6       0.41\n",
            "         tennis racket        128          7      0.726      0.387      0.487       0.33\n",
            "                bottle        128         18      0.448      0.389      0.376      0.208\n",
            "            wine glass        128         16      0.743      0.362      0.584      0.333\n",
            "                   cup        128         36       0.58      0.278      0.404       0.29\n",
            "                  fork        128          6      0.527      0.167      0.246      0.184\n",
            "                 knife        128         16      0.564        0.5       0.59       0.36\n",
            "                 spoon        128         22      0.597      0.182      0.328       0.19\n",
            "                  bowl        128         28      0.648      0.643      0.618      0.491\n",
            "                banana        128          1          0          0      0.124     0.0379\n",
            "              sandwich        128          2      0.249        0.5      0.308      0.308\n",
            "                orange        128          4          1       0.31      0.995      0.623\n",
            "              broccoli        128         11      0.374      0.182      0.249      0.203\n",
            "                carrot        128         24      0.648      0.458      0.572      0.362\n",
            "               hot dog        128          2      0.351      0.553      0.745      0.721\n",
            "                 pizza        128          5      0.644          1      0.995      0.843\n",
            "                 donut        128         14      0.657          1       0.94      0.864\n",
            "                  cake        128          4      0.618          1      0.945      0.845\n",
            "                 chair        128         35      0.506      0.514      0.442      0.239\n",
            "                 couch        128          6      0.463        0.5      0.706      0.555\n",
            "          potted plant        128         14       0.65      0.643      0.711      0.472\n",
            "                   bed        128          3      0.698      0.667      0.789      0.625\n",
            "          dining table        128         13      0.432      0.615      0.485      0.366\n",
            "                toilet        128          2      0.615        0.5      0.695      0.676\n",
            "                    tv        128          2      0.373       0.62      0.745      0.696\n",
            "                laptop        128          3          1          0      0.451      0.361\n",
            "                 mouse        128          2          1          0     0.0625    0.00625\n",
            "                remote        128          8      0.843        0.5      0.605      0.529\n",
            "            cell phone        128          8          0          0     0.0549     0.0393\n",
            "             microwave        128          3      0.435      0.667      0.806      0.718\n",
            "                  oven        128          5      0.412        0.4      0.339       0.27\n",
            "                  sink        128          6       0.35      0.167      0.182      0.129\n",
            "          refrigerator        128          5      0.589        0.4      0.604      0.452\n",
            "                  book        128         29      0.629      0.103      0.346      0.178\n",
            "                 clock        128          9      0.788       0.83      0.875       0.74\n",
            "                  vase        128          2      0.376          1      0.828      0.795\n",
            "              scissors        128          1          1          0      0.249     0.0746\n",
            "            teddy bear        128         21      0.877      0.333      0.591      0.394\n",
            "            toothbrush        128          5      0.743        0.6      0.638      0.374\n",
            "Speed: 5.6ms preprocess, 265.3ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo train model=yolov8n.pt data=coco128.yaml epochs=3 imgsz=640"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MV0BPhDvN9lf",
        "outputId": "b50d0673-2ee7-405d-ec36-cf9b8199aa14"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.140 🚀 Python-3.10.6 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=coco128.yaml, epochs=3, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "Model summary: 225 layers, 3157200 parameters, 3157184 gradients\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100% 128/128 [00:00<?, ?it/s]\n",
            "Plotting labels to runs/detect/train2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        1/3         0G      1.166      1.461      1.243        294        640: 100% 8/8 [02:01<00:00, 15.22s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:38<00:00,  9.56s/it]\n",
            "                   all        128        929      0.661      0.519      0.614      0.458\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        2/3         0G       1.22      1.464       1.27        251        640: 100% 8/8 [01:52<00:00, 14.09s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:36<00:00,  9.11s/it]\n",
            "                   all        128        929      0.647      0.553      0.626      0.466\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        3/3         0G      1.127      1.385      1.218        158        640: 100% 8/8 [01:48<00:00, 13.60s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:43<00:00, 10.89s/it]\n",
            "                   all        128        929      0.678      0.533      0.631      0.471\n",
            "\n",
            "3 epochs completed in 0.130 hours.\n",
            "Optimizer stripped from runs/detect/train2/weights/last.pt, 6.5MB\n",
            "Optimizer stripped from runs/detect/train2/weights/best.pt, 6.5MB\n",
            "\n",
            "Validating runs/detect/train2/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.140 🚀 Python-3.10.6 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "Model summary (fused): 168 layers, 3151904 parameters, 0 gradients\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:34<00:00,  8.63s/it]\n",
            "                   all        128        929       0.68      0.532      0.631      0.471\n",
            "                person        128        254      0.843      0.665      0.778      0.544\n",
            "               bicycle        128          6      0.583      0.333      0.326      0.279\n",
            "                   car        128         46      0.757      0.217      0.278      0.187\n",
            "            motorcycle        128          5      0.695        0.8      0.938      0.743\n",
            "              airplane        128          6      0.785      0.833      0.894      0.677\n",
            "                   bus        128          7      0.753      0.714      0.722      0.641\n",
            "                 train        128          3      0.549      0.667      0.806      0.746\n",
            "                 truck        128         12          1      0.453      0.519      0.333\n",
            "                  boat        128          6      0.404      0.237      0.445      0.306\n",
            "         traffic light        128         14      0.743      0.208      0.201      0.138\n",
            "             stop sign        128          2      0.896          1      0.995      0.697\n",
            "                 bench        128          9      0.824      0.523      0.632      0.369\n",
            "                  bird        128         16       0.92      0.719      0.882      0.526\n",
            "                   cat        128          4      0.873          1      0.995      0.795\n",
            "                   dog        128          9      0.651      0.889      0.826       0.61\n",
            "                 horse        128          2      0.618          1      0.995      0.512\n",
            "              elephant        128         17      0.944      0.824      0.916      0.687\n",
            "                  bear        128          1      0.638          1      0.995      0.995\n",
            "                 zebra        128          4      0.861          1      0.995      0.965\n",
            "               giraffe        128          9      0.819      0.889      0.963      0.731\n",
            "              backpack        128          6      0.658      0.333       0.38      0.232\n",
            "              umbrella        128         18      0.832        0.5      0.678       0.45\n",
            "               handbag        128         19          1          0      0.216      0.119\n",
            "                   tie        128          7      0.695      0.656      0.641      0.473\n",
            "              suitcase        128          4      0.582      0.704      0.828      0.592\n",
            "               frisbee        128          5      0.636        0.8      0.759      0.664\n",
            "                  skis        128          1      0.646          1      0.995      0.497\n",
            "             snowboard        128          7      0.689      0.714      0.745      0.545\n",
            "           sports ball        128          6      0.714      0.429      0.514      0.283\n",
            "                  kite        128         10      0.807      0.422      0.584      0.212\n",
            "          baseball bat        128          4      0.478       0.25      0.378      0.212\n",
            "        baseball glove        128          7      0.659      0.429      0.429      0.295\n",
            "            skateboard        128          5      0.792        0.6        0.6      0.426\n",
            "         tennis racket        128          7      0.524      0.286      0.465      0.319\n",
            "                bottle        128         18      0.514      0.333      0.355      0.206\n",
            "            wine glass        128         16      0.728      0.336      0.567      0.331\n",
            "                   cup        128         36      0.625       0.25      0.385      0.274\n",
            "                  fork        128          6      0.604      0.167      0.249      0.188\n",
            "                 knife        128         16      0.711        0.5      0.616      0.375\n",
            "                 spoon        128         22      0.546      0.182      0.366      0.194\n",
            "                  bowl        128         28      0.648      0.679      0.644      0.529\n",
            "                banana        128          1          0          0      0.166     0.0473\n",
            "              sandwich        128          2       0.11       0.11      0.448      0.447\n",
            "                orange        128          4          1      0.345      0.995      0.669\n",
            "              broccoli        128         11      0.436      0.182      0.253      0.209\n",
            "                carrot        128         24      0.741        0.5      0.682      0.433\n",
            "               hot dog        128          2      0.485          1      0.828      0.795\n",
            "                 pizza        128          5      0.859          1      0.995      0.844\n",
            "                 donut        128         14      0.646          1      0.934      0.849\n",
            "                  cake        128          4      0.817          1      0.995       0.88\n",
            "                 chair        128         35      0.557      0.502      0.456      0.261\n",
            "                 couch        128          6      0.736      0.472      0.677      0.515\n",
            "          potted plant        128         14      0.778      0.643      0.763      0.519\n",
            "                   bed        128          3      0.753      0.667      0.863      0.665\n",
            "          dining table        128         13      0.503      0.615      0.512      0.413\n",
            "                toilet        128          2      0.641        0.5      0.828      0.796\n",
            "                    tv        128          2      0.449        0.5      0.745      0.696\n",
            "                laptop        128          3          1      0.401      0.727      0.576\n",
            "                 mouse        128          2          1          0     0.0419    0.00419\n",
            "                remote        128          8       0.83        0.5      0.575      0.494\n",
            "            cell phone        128          8          0          0     0.0529     0.0354\n",
            "             microwave        128          3      0.626      0.667      0.863      0.753\n",
            "                  oven        128          5      0.502        0.4      0.341      0.272\n",
            "                  sink        128          6      0.378      0.167      0.204       0.14\n",
            "          refrigerator        128          5      0.691        0.4      0.669      0.546\n",
            "                  book        128         29      0.606      0.107      0.351      0.189\n",
            "                 clock        128          9       0.78      0.788      0.894      0.756\n",
            "                  vase        128          2      0.399          1      0.828      0.795\n",
            "              scissors        128          1          1          0      0.249     0.0746\n",
            "            teddy bear        128         21       0.91      0.333      0.632      0.429\n",
            "            toothbrush        128          5      0.777        0.4       0.75      0.467\n",
            "Speed: 4.3ms preprocess, 238.1ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo export model=yolov8n.pt format=torchscript"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNoi8KxFN9ft",
        "outputId": "cecb250e-7c13-4faf-b589-6183ad73c947"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.140 🚀 Python-3.10.6 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (6.2 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.0.1+cu118...\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success ✅ 4.6s, saved as 'yolov8n.torchscript' (12.4 MB)\n",
            "\n",
            "Export complete (6.5s)\n",
            "Results saved to \u001b[1m/content\u001b[0m\n",
            "Predict:         yolo predict task=detect model=yolov8n.torchscript imgsz=640 \n",
            "Validate:        yolo val task=detect model=yolov8n.torchscript imgsz=640 data=coco.yaml \n",
            "Visualize:       https://netron.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a model\n",
        "model = YOLO('yolov8n.yaml')  # build a new model from scratch\n",
        "model = YOLO('yolov8n.pt')  # load a pretrained model (recommended for training)\n",
        "\n",
        "# Use the model\n",
        "results = model.train(data='coco128.yaml', epochs=3)  # train the model\n",
        "results = model.val()  # evaluate model performance on the validation set\n",
        "results = model('https://ultralytics.com/images/bus.jpg')  # predict on an image\n",
        "results = model.export(format='onnx')  # export the model to ONNX format"
      ],
      "metadata": {
        "id": "Tmz64LctN9bT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.detection model (Topics used)\n",
        "model = YOLO('yolov8n.pt')  # load a pretrained YOLOv8n detection model\n",
        "model.train(data='coco128.yaml', epochs=3)  # train the model\n",
        "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
      ],
      "metadata": {
        "id": "NRzG9BH2N9WB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. segmentation model\n",
        "model = YOLO('yolov8n-seg.pt')  # load a pretrained YOLOv8n segmentation model\n",
        "model.train(data='coco128-seg.yaml', epochs=3)  # train the model\n",
        "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
      ],
      "metadata": {
        "id": "_Nfv3qfKSfdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. classifications model\n",
        "model = YOLO('yolov8n-cls.pt')  # load a pretrained YOLOv8n classification model\n",
        "model.train(data='mnist160', epochs=3)  # train the model\n",
        "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
      ],
      "metadata": {
        "id": "W-lOLqQUSfXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. pose model\n",
        "model = YOLO('yolov8n-pose.pt')  # load a pretrained YOLOv8n classification model\n",
        "model.train(data='coco8-pose.yaml', epochs=3)  # train the model\n",
        "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
      ],
      "metadata": {
        "id": "ncutytHuSfVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Appendix\n",
        "(Not use)"
      ],
      "metadata": {
        "id": "qvVz-ws_Tv0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Git clone and run tests on updates branch\n",
        "!git clone https://github.com/ultralytics/ultralytics -b main\n",
        "%pip install -qe ultralytics\n",
        "\n",
        "!pytest ultralytics/tests # Run tests (Git clone only)\n",
        "\n",
        "# Validate multiple models\n",
        "for x in 'nsmlx':\n",
        "  !yolo val model=yolov8{x}.pt data=coco.yaml"
      ],
      "metadata": {
        "id": "b7RhlAxXSfTu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}